{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "BLOSUM1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BLOSUM2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BLOSUM3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BLOSUM4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BLOSUM5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BLOSUM6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BLOSUM7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BLOSUM8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BLOSUM9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BLOSUM10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hmoment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hydrophobicity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "KF1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "KF2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "KF3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "KF4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "KF5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "KF6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "KF7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "KF8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "KF9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "KF10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MSWHIM1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MSWHIM2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MSWHIM3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mw",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mz",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ProtFP1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ProtFP2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ProtFP3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ProtFP4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ProtFP5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ProtFP6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ProtFP7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ProtFP8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ST1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ST2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ST3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ST4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ST5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ST6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ST7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ST8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "T1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "T2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "T3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "T4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "T5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VHSE1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VHSE2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VHSE3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VHSE4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VHSE5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VHSE6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VHSE7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VHSE8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Z1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Z2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Z3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Z4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Z5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b5d4e57b-a5e5-41a1-9282-cd259db00182",
       "rows": [
        [
         "0",
         "0.35",
         "-0.392",
         "-0.02",
         "-0.246",
         "0.146",
         "0.372",
         "0.432",
         "0.256",
         "0.302",
         "-0.184",
         "-0.2496",
         "0.0564",
         "-0.2572",
         "0.8032",
         "-0.3172",
         "0.199",
         "0.647938467256028",
         "-0.38",
         "-0.302",
         "-0.43",
         "0.026",
         "0.44",
         "0.342",
         "-0.82",
         "0.518",
         "0.526",
         "-0.35",
         "-0.12",
         "-0.594",
         "0.182",
         "-0.084",
         "515.65354",
         "258.678831",
         "10.8053935283569",
         "-1.84",
         "-1.078",
         "0.192",
         "1.488",
         "-0.7",
         "1.302",
         "0.256",
         "0.336",
         "-1.0378",
         "-0.2658",
         "-0.1132",
         "0.1166",
         "-0.473",
         "-0.4866",
         "0.272",
         "0.817",
         "-5.83",
         "0.312",
         "-0.604",
         "0.802",
         "0.976",
         "-0.224",
         "-0.276",
         "-0.456",
         "0.232",
         "0.614",
         "-0.472",
         "1.094",
         "-0.338",
         "0.596",
         "-1.266",
         "-1.146",
         "0.236",
         "0.36",
         "0"
        ],
        [
         "1",
         "-0.17",
         "-0.61",
         "-0.012",
         "0.0",
         "-0.138",
         "0.408",
         "0.364",
         "0.27",
         "0.222",
         "0.028",
         "0.3326",
         "0.0492",
         "-0.1524",
         "0.8834",
         "-0.3226",
         "0.053",
         "0.57283098575372",
         "1.3",
         "-0.38",
         "-0.626",
         "0.43",
         "-0.054",
         "-0.074",
         "-0.49",
         "0.122",
         "0.644",
         "-0.122",
         "-0.596",
         "-0.674",
         "0.332",
         "-0.254",
         "500.63884",
         "251.173381",
         "9.70001568333414",
         "0.474",
         "-2.424",
         "-0.446",
         "1.106",
         "-0.522",
         "0.964",
         "0.612",
         "-0.022",
         "-1.094",
         "-0.5168",
         "-0.2424",
         "0.1102",
         "-0.476",
         "-0.4706",
         "0.1392",
         "0.5536",
         "-6.162",
         "-0.212",
         "-0.296",
         "1.0",
         "0.976",
         "0.264",
         "-0.444",
         "-0.536",
         "-0.288",
         "0.346",
         "-0.928",
         "0.736",
         "-0.39",
         "-0.64",
         "-1.79",
         "-0.99",
         "-0.23",
         "0.35",
         "0"
        ],
        [
         "2",
         "0.138",
         "-0.568",
         "0.246",
         "-0.076",
         "0.03",
         "0.39",
         "0.522",
         "0.22",
         "0.538",
         "0.052",
         "0.0692",
         "0.1062",
         "-0.516",
         "1.014",
         "-0.2708",
         "-0.1524",
         "0.623376015181423",
         "0.76",
         "-0.546",
         "-0.928",
         "-0.122",
         "0.046",
         "-0.152",
         "-0.652",
         "0.248",
         "0.526",
         "-0.212",
         "-0.336",
         "-0.638",
         "0.206",
         "-0.328",
         "458.55824",
         "230.149906",
         "9.70001568333414",
         "-0.862",
         "-3.066",
         "-0.374",
         "1.228",
         "-0.532",
         "1.232",
         "-0.06",
         "0.356",
         "-1.2474",
         "-0.473",
         "-0.298",
         "0.177",
         "-0.4878",
         "-1.1346",
         "0.2236",
         "0.9506",
         "-7.134",
         "-0.482",
         "-0.14",
         "0.928",
         "1.47",
         "0.04",
         "-0.638",
         "-0.866",
         "-0.112",
         "0.29",
         "-0.788",
         "0.84",
         "-0.46",
         "0.186",
         "-1.908",
         "-0.528",
         "-0.09",
         "0.558",
         "0"
        ],
        [
         "3",
         "0.35",
         "-0.392",
         "-0.02",
         "-0.246",
         "0.146",
         "0.372",
         "0.432",
         "0.256",
         "0.302",
         "-0.184",
         "-0.2496",
         "0.0564",
         "-0.2572",
         "0.8032",
         "-0.3172",
         "0.199",
         "0.744358586242552",
         "-0.38",
         "-0.302",
         "-0.43",
         "0.026",
         "0.44",
         "0.342",
         "-0.82",
         "0.518",
         "0.526",
         "-0.35",
         "-0.12",
         "-0.594",
         "0.182",
         "-0.084",
         "515.65354",
         "258.678831",
         "10.8053935283569",
         "-1.84",
         "-1.078",
         "0.192",
         "1.488",
         "-0.7",
         "1.302",
         "0.256",
         "0.336",
         "-1.0378",
         "-0.2658",
         "-0.1132",
         "0.1166",
         "-0.473",
         "-0.4866",
         "0.272",
         "0.817",
         "-5.83",
         "0.312",
         "-0.604",
         "0.802",
         "0.976",
         "-0.224",
         "-0.276",
         "-0.456",
         "0.232",
         "0.614",
         "-0.472",
         "1.094",
         "-0.338",
         "0.596",
         "-1.266",
         "-1.146",
         "0.236",
         "0.36",
         "0"
        ],
        [
         "4",
         "-0.112",
         "-0.652",
         "-0.518",
         "-0.188",
         "0.136",
         "0.19",
         "0.164",
         "0.122",
         "0.256",
         "-0.19",
         "0.0962",
         "0.6074",
         "0.2358",
         "0.7042",
         "-0.1334",
         "0.5136",
         "0.778973054153558",
         "0.6",
         "-0.74",
         "-0.07",
         "0.43",
         "0.318",
         "0.214",
         "-0.792",
         "0.088",
         "0.156",
         "0.114",
         "-0.568",
         "-0.714",
         "0.404",
         "0.016",
         "571.76104",
         "286.710131",
         "10.8053935283569",
         "0.616",
         "0.32",
         "-1.142",
         "1.976",
         "-0.706",
         "0.664",
         "0.586",
         "0.174",
         "-0.826",
         "-0.4642",
         "-0.1462",
         "-0.0174",
         "-0.4078",
         "0.395",
         "0.211",
         "0.1598",
         "-4.558",
         "0.498",
         "-0.61",
         "0.932",
         "0.284",
         "0.07",
         "0.0019999999999999",
         "0.13",
         "-0.584",
         "0.78",
         "-0.558",
         "0.66",
         "-0.096",
         "-0.592",
         "-0.8",
         "-1.56",
         "0.232",
         "0.488",
         "0"
        ]
       ],
       "shape": {
        "columns": 69,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLOSUM1</th>\n",
       "      <th>BLOSUM2</th>\n",
       "      <th>BLOSUM3</th>\n",
       "      <th>BLOSUM4</th>\n",
       "      <th>BLOSUM5</th>\n",
       "      <th>BLOSUM6</th>\n",
       "      <th>BLOSUM7</th>\n",
       "      <th>BLOSUM8</th>\n",
       "      <th>BLOSUM9</th>\n",
       "      <th>BLOSUM10</th>\n",
       "      <th>...</th>\n",
       "      <th>VHSE5</th>\n",
       "      <th>VHSE6</th>\n",
       "      <th>VHSE7</th>\n",
       "      <th>VHSE8</th>\n",
       "      <th>Z1</th>\n",
       "      <th>Z2</th>\n",
       "      <th>Z3</th>\n",
       "      <th>Z4</th>\n",
       "      <th>Z5</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.350</td>\n",
       "      <td>-0.392</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.302</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.472</td>\n",
       "      <td>1.094</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>0.596</td>\n",
       "      <td>-1.266</td>\n",
       "      <td>-1.146</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.170</td>\n",
       "      <td>-0.610</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346</td>\n",
       "      <td>-0.928</td>\n",
       "      <td>0.736</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>-0.640</td>\n",
       "      <td>-1.790</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>0.246</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290</td>\n",
       "      <td>-0.788</td>\n",
       "      <td>0.840</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>0.186</td>\n",
       "      <td>-1.908</td>\n",
       "      <td>-0.528</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.350</td>\n",
       "      <td>-0.392</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.302</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.472</td>\n",
       "      <td>1.094</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>0.596</td>\n",
       "      <td>-1.266</td>\n",
       "      <td>-1.146</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.652</td>\n",
       "      <td>-0.518</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.256</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780</td>\n",
       "      <td>-0.558</td>\n",
       "      <td>0.660</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.592</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-1.560</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BLOSUM1  BLOSUM2  BLOSUM3  BLOSUM4  BLOSUM5  BLOSUM6  BLOSUM7  BLOSUM8  \\\n",
       "0    0.350   -0.392   -0.020   -0.246    0.146    0.372    0.432    0.256   \n",
       "1   -0.170   -0.610   -0.012    0.000   -0.138    0.408    0.364    0.270   \n",
       "2    0.138   -0.568    0.246   -0.076    0.030    0.390    0.522    0.220   \n",
       "3    0.350   -0.392   -0.020   -0.246    0.146    0.372    0.432    0.256   \n",
       "4   -0.112   -0.652   -0.518   -0.188    0.136    0.190    0.164    0.122   \n",
       "\n",
       "   BLOSUM9  BLOSUM10  ...  VHSE5  VHSE6  VHSE7  VHSE8     Z1     Z2     Z3  \\\n",
       "0    0.302    -0.184  ...  0.614 -0.472  1.094 -0.338  0.596 -1.266 -1.146   \n",
       "1    0.222     0.028  ...  0.346 -0.928  0.736 -0.390 -0.640 -1.790 -0.990   \n",
       "2    0.538     0.052  ...  0.290 -0.788  0.840 -0.460  0.186 -1.908 -0.528   \n",
       "3    0.302    -0.184  ...  0.614 -0.472  1.094 -0.338  0.596 -1.266 -1.146   \n",
       "4    0.256    -0.190  ...  0.780 -0.558  0.660 -0.096 -0.592 -0.800 -1.560   \n",
       "\n",
       "      Z4     Z5  label  \n",
       "0  0.236  0.360      0  \n",
       "1 -0.230  0.350      0  \n",
       "2 -0.090  0.558      0  \n",
       "3  0.236  0.360      0  \n",
       "4  0.232  0.488      0  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/sequence_descriptors_labels.csv\")\n",
    "data = data.iloc[:, 5:]\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, data, target_column):\n",
    "        self.data = data\n",
    "        self.features = self.data.drop(columns=[target_column]).values  # Input features\n",
    "        self.labels = self.data[target_column].values  # Target values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return x, y  # Returns a tuple (features, label)\n",
    "\n",
    "# Example Usage\n",
    "dataset = CSVDataset(data, target_column=\"label\")  # Replace with your CSV file\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Split data\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(68, 36),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(36, 36),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(36, 3),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=68, out_features=36, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=36, out_features=36, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=36, out_features=3, bias=True)\n",
      "    (5): Softmax(dim=None)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/TH External/Uni (Honours)/_Class Work/Honours Science 1/pytorch-mnist/.env/lib/python3.13/site-packages/torch/nn/modules/module.py:1739: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 68, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y.long())\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y.long()).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.082701  [   32/26139]\n",
      "loss: 0.895220  [ 6432/26139]\n",
      "loss: 1.082695  [12832/26139]\n",
      "loss: 1.176481  [19232/26139]\n",
      "loss: 0.895161  [25632/26139]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/TH External/Uni (Honours)/_Class Work/Honours Science 1/pytorch-mnist/.env/lib/python3.13/site-packages/torch/nn/modules/module.py:1739: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.957660  [32032/26139]\n",
      "loss: 0.863950  [38432/26139]\n",
      "loss: 1.145199  [44832/26139]\n",
      "loss: 0.863958  [51232/26139]\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 1.001269 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.082702  [   32/26139]\n",
      "loss: 1.020191  [ 6432/26139]\n",
      "loss: 0.926443  [12832/26139]\n",
      "loss: 0.957697  [19232/26139]\n",
      "loss: 1.145201  [25632/26139]\n",
      "loss: 0.957696  [32032/26139]\n",
      "loss: 1.020194  [38432/26139]\n",
      "loss: 1.020188  [44832/26139]\n",
      "loss: 1.020187  [51232/26139]\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 1.001269 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.020236  [   32/26139]\n",
      "loss: 0.926447  [ 6432/26139]\n",
      "loss: 0.926445  [12832/26139]\n",
      "loss: 1.051381  [19232/26139]\n",
      "loss: 1.051445  [25632/26139]\n",
      "loss: 0.863944  [32032/26139]\n",
      "loss: 1.020197  [38432/26139]\n",
      "loss: 1.082652  [44832/26139]\n",
      "loss: 1.020159  [51232/26139]\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 1.001269 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.895241  [   32/26139]\n",
      "loss: 1.020195  [ 6432/26139]\n",
      "loss: 1.082695  [12832/26139]\n",
      "loss: 0.895193  [19232/26139]\n",
      "loss: 0.957670  [25632/26139]\n",
      "loss: 0.988984  [32032/26139]\n",
      "loss: 0.988958  [38432/26139]\n",
      "loss: 1.051445  [44832/26139]\n",
      "loss: 0.926444  [51232/26139]\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 1.001269 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.832733  [   32/26139]\n",
      "loss: 0.957697  [ 6432/26139]\n",
      "loss: 0.988971  [12832/26139]\n",
      "loss: 0.988966  [19232/26139]\n",
      "loss: 0.926440  [25632/26139]\n",
      "loss: 0.988946  [32032/26139]\n",
      "loss: 1.051433  [38432/26139]\n",
      "loss: 1.113945  [44832/26139]\n",
      "loss: 0.988964  [51232/26139]\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 1.001269 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.988945  [   32/26139]\n",
      "loss: 0.926445  [ 6432/26139]\n",
      "loss: 0.957659  [12832/26139]\n",
      "loss: 1.051446  [19232/26139]\n",
      "loss: 1.082695  [25632/26139]\n",
      "loss: 1.020190  [32032/26139]\n",
      "loss: 0.988944  [38432/26139]\n",
      "loss: 1.020191  [44832/26139]\n",
      "loss: 0.988917  [51232/26139]\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 1.001269 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.113944  [   32/26139]\n",
      "loss: 1.238944  [ 6432/26139]\n",
      "loss: 1.082696  [12832/26139]\n",
      "loss: 1.145195  [19232/26139]\n",
      "loss: 0.957689  [25632/26139]\n",
      "loss: 1.051446  [32032/26139]\n",
      "loss: 1.082694  [38432/26139]\n",
      "loss: 1.082695  [44832/26139]\n",
      "loss: 0.957689  [51232/26139]\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 1.001269 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.082695  [   32/26139]\n",
      "loss: 1.051436  [ 6432/26139]\n",
      "loss: 0.957689  [12832/26139]\n",
      "loss: 1.176417  [19232/26139]\n",
      "loss: 0.988912  [25632/26139]\n",
      "loss: 1.113945  [32032/26139]\n",
      "loss: 1.020192  [38432/26139]\n",
      "loss: 1.051446  [44832/26139]\n",
      "loss: 0.957694  [51232/26139]\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 1.001269 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.020202  [   32/26139]\n",
      "loss: 1.020155  [ 6432/26139]\n",
      "loss: 1.020181  [12832/26139]\n",
      "loss: 0.957693  [19232/26139]\n",
      "loss: 0.988942  [25632/26139]\n",
      "loss: 0.957693  [32032/26139]\n",
      "loss: 1.051441  [38432/26139]\n",
      "loss: 0.988988  [44832/26139]\n",
      "loss: 0.988948  [51232/26139]\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 1.001269 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.895196  [   32/26139]\n",
      "loss: 0.988957  [ 6432/26139]\n",
      "loss: 0.926443  [12832/26139]\n",
      "loss: 1.051445  [19232/26139]\n",
      "loss: 0.863948  [25632/26139]\n",
      "loss: 0.988925  [32032/26139]\n",
      "loss: 1.051445  [38432/26139]\n",
      "loss: 1.113943  [44832/26139]\n",
      "loss: 0.988939  [51232/26139]\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 1.001269 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    test_loop(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
